# ai-case-study
Case Study For AI Company
## Overview and Origin

* Name of Company
  Anthropic

* When was the company incorporated?
  2021

* Who are the founders of the company?
  Dario Amodei, CEO, and Daniela Amodei, president, are former vice presidents of OpenAI (Guo, Para 5).

* How did the idea for the company (or project) come about?
  The company's idea came about when Dario Amodei co-authored a paper named “Concrete Problems in AI Safety” that discusses the concerns noted about the use of neural networks. “The paper introduced the notion of side effects and unsafe exploration of the capabilities of different models (Gui, Para 5).” Many of the workers who used to work for OpenAI in 2019 served as the precursors to the Anthropic platform. This is caused by the change of the OpenAI platform from non-profit to corporate status. It sparked heated debates among the engineers who migrated away from the company to form Anthropic. “Open AI started out as a non-profit meant to democratize AI. Obviously, when you get $1 billion, you have to generate a return. I think their trajectory has become more corporate,” according to Dario in an interview.
  
* How is the company funded? How much funding have they received?
  Anthropic was funded by a myriad of investors, including Estonian multibillionaire computer programmer Jaan Tallinn. Google and Amazon provided funding totaling $6 billion. Menlo Ventures closed an additional deal that led to an investment of $750 million. “All told, the A.I. start-up hauled in $7.3 billion in a year. Its five funding deals stood out not just for their speed and size but for their unusual structures (Griffith et al., Para 4).”

## Business Activities

* What specific problem is the company or project trying to solve?
  The company is attempting to resolve a specific problem: unethical data practices with copyrighted material. They aim to fix training data errors made by OpenAI and Meta, particularly those related to permission use and distribution. “Anthropic’s research concerns the ethicality of its foundational models, meaning not much can be done by the model to alter its own training data. As such, avoiding conflicts with lax data practices is a prerequisite to maintaining its commitment to helpful and harmless AI (Guo, Para 80).”

* Who is the company's intended customer? Is there any information about the market size of this set of customers?
  The company’s intended customers are enterprise businesses that specialize in Coaching, Legal Services, Customer Sales, and Back-Office operations. Examples can include Bridgewater, Jane Street, Asana, and Robin AI. The market size for this group is projected to grow in productivity for nearly two-thirds of professions by the early 2040s. “As of Q1 2023, over 1 in 10 adults in the UK used generative AI in the workplace daily (Guo, Para 46).”

* What solution does this company offer that their competitors do not or cannot offer? (What is the unfair advantage they utilize?)
  This company's solution is an ethical approach known as Constitutional AI. This involves information safety and data filtering that aligns with valid human input. It also involves the understanding of social dynamics with intuitive prompts and controlled environments.

* Which technologies are they currently using, and how are they implementing them? (This may take a little bit of sleuthing&mdash;you may want to search the company’s engineering blog or use sites like Stackshare to find this information.)
  Anthropic is currently using a family of foundational models that are similar to Chat GPT from Open AI. They are known as Claude and vary in the different tiers of token prompt distribution. The technologies implemented are deployed in Amazon Web Services and focus on training models with custom integration of preexisting infrastructure.

##Landscape

* What field is the company in?
  AI safety and research. Anthropic builds dependable and interpretable systems for AI Machine Learning engineers. A team of dedicated professionals conducts research to apply safety techniques online and on a massive scale.
  
* What have been the major trends and innovations of this field over the last 5&ndash;10 years?
  One of the few trends and innovations is tech companies like Amazon, Google, and Anthropic, which recently volunteered to aid the White House in initiating a legislature for AI risk management (Torres, Para 1-3). This coincides with legal proceedings that create an executive order safeguarding AI development. It can also help avoid exploitation and malicious intent of data usage.

* What are the other major companies in this field?
  OpenAI, Google, Inflection, and Cohere.

## Results

* What has been the business impact of this company so far?
  Having an extended range of business partners that utilize the Claude AI model interface. This includes Quora, Notion, Zoom, DuckDuckGo, and SK Telecom. “In April 2023, Anthropic announced a partnership with Scale AI, allowing the two to provide full stack generative AI solutions to its customers (Guo, Para 70).”

* What are some of the core metrics that companies in this field use to measure success? How is your company performing based on these metrics?
  Some of the core metrics these companies use are accuracy and performance with speed and efficiency. These metrics help them assess how well they can track the predictions of processed data. They can also measure the precision and scalability of user input engagement. Anthropic’s Claude system outpaced the accuracy of Chat GPT and Gemini Ultra. Graduate-level reasoning is at 50.4% compared to GPT-4 at 35.7%.

* How is your company performing relative to competitors in the same field?
  According to this Medium article written by Ahmed Fessi, it states, “The benchmark made with Claude 3 (Opus) shows better accuracy against GPT4 on Undergraduate level knowledge (86,8% vs 86,4%), Graduate level reasoning (50,4% vs 35,7%), Grade school math (95% vs 92%), Math problem solving (60,1% vs 52,9%), Multilingual Math (90,7% vs 74,5%), Code (84,9% vs 67%), Reasoning over text (83,1% vs 80,9%) and so on (Fessi, Para 6).”

## Recommendations

* If you were to advise the company, what products or services would you suggest they offer? (This could be something that a competitor offers, or use your imagination!)
  One product I would suggest for the company since they mentioned the constitutionality of AI testing, is creating a generative security bot that functions as a user firewall protector. This, in turn, would garner public interest in seeking a better alternative to protect digital privacy.

* Why do you think that offering this product or service would benefit the company?
  This service would benefit the company by improving its current risk assessment methods. It can also attract the attention of private investors, who can accelerate the development of security algorithms within the virtual space.

* What technologies would this additional product or service utilize?
  A combination of cybersecurity and GPT protocols that can mirror the upcoming Claude 3 model. Having it function on a national security level could significantly reduce cyber threats online.

* Why are these technologies appropriate for your solution?
  These technologies are appropriate for safeguarding the integrity of the Internet of Things (IoT). By making it more user-friendly and compatible with its intentions, people would be inclined to disseminate the material on a broader scale. This can be attributed to more audience members becoming more security conscious about their next approach.
  
## References
https://www.fool.com/investing/stock-market/market-sectors/information-technology/ai-stocks/ai-startups/
https://www.anthropic.com/
https://research.contrary.com/reports/anthropic?head=;;traction
https://www.nytimes.com/2024/02/20/technology/anthropic-funding-ai.html
https://medium.com/@entrustech/anthropic-ai-what-you-need-to-know-and-how-to-use-it-e036a4267b0f#:~:text=The%20Anthropic%20Difference&text=Anthropic%20takes%20a%20different%20approach,helpful%2C%20harmless%2C%20and%20honest.
https://aws.amazon.com/generative-ai/?gclid=CjwKCAjwte-vBhBFEiwAQSv_xYQQ8pc1mXZFuXhuwBJuS5bN8FEpLuobD9m9b9WGDeCh29p2i3YolhoCOacQAvD_BwE&trk=37f16211-953d-4266-8bd3-43e57ebe6584&sc_channel=ps&ef_id=CjwKCAjwte-vBhBFEiwAQSv_xYQQ8pc1mXZFuXhuwBJuS5bN8FEpLuobD9m9b9WGDeCh29p2i3YolhoCOacQAvD_BwE:G:s&s_kwcid=AL!4422!3!692817052481!p!!g!!anthropic!20901655892!158876929119
https://www.youtube.com/watch?v=c8Ijax2nQf8
https://www.ciodive.com/news/white-house-AI-salesforce-nvidia-IBM/693604/
https://medium.com/@AhmedF/anthropics-claude-3-beats-gpt-4-across-main-metrics-feb72963564a
